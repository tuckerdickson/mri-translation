{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b79360d-dbe0-4706-8a88-dfc61cd3571b",
   "metadata": {},
   "source": [
    "# Phase II: Unsupervised Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac53120-4dca-402a-99f6-f13ec41655aa",
   "metadata": {},
   "source": [
    "### Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aa24fe4-5540-4ab2-b092-6b72b2bb9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os     \n",
    "import glob             \n",
    "import random                         \n",
    "import nibabel as nib                    \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt              \n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from generator import Generator\n",
    "from discriminator import Discriminator\n",
    "from dataset import MRIDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30fb56b-676f-4c5c-b6e2-fec6b86f741f",
   "metadata": {},
   "source": [
    "### Unzip Data Archive\n",
    "This cell unpacks the archive.zip file in the data directory. If this file has already been unpacked, leave this cell commented out, as it takes several minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d865c2e-f977-4a84-85ee-0b40082c757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.unpack_archive('data/archive.zip', 'data/archive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e6336-1224-4951-9e08-3bda86ae3d2a",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "\n",
    "This function is used to train the cycle-GAN model. It does this in three parts:\n",
    "1. Train the T1 discriminator by feeding it a real T1 and a fake T1, and measuring the loss.\n",
    "2. Train the T2 discriminator by feeding it a real T2 and a fake T2, and measuring the loss.\n",
    "3. Train the T1 and T2 generators by measuring their adverserial losses (the generator's ability to fool the discriminator) and their cycle losses (the generator's ability to create cycle-consistent images).\n",
    "\n",
    "The parameters to this function are as follows:\n",
    "- gen1: generates a T1 using T2 as input (T2->T1)\n",
    "- gen2: generates a T2 using T1 as input (T1->T2)\n",
    "- genOpt: optimizer for generator\n",
    "- disc1: classifies real/fake T1 \n",
    "- disc2: classifies real/fake T2 \n",
    "- discOpt: optimizer for discriminator\n",
    "- mse: mean-square error loss function\n",
    "- mae: mean-absolute error loss function\n",
    "- loader: data loader\n",
    "- device: target device to run on\n",
    "- plot: set to True if you wish to display real and generated images on the final iteration, otherwise False.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06e30502-4108-4059-90b2-5843ff2f33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen1, gen2, genOpt, disc1, disc2, discOpt, mse, mae, loader, device, plot=False):\n",
    "    # iterate through the entire dataset\n",
    "    for index, (t1, t2) in enumerate(loader):\n",
    "        t1 = t1.to(device)\n",
    "        t2 = t2.to(device)\n",
    "        \n",
    "        # ------------------- t1 discriminator forward pass ------------------- #\n",
    "        # use the t2 -> t1 generator to generate a fake t1\n",
    "        t1GenFake = gen1(t2)\n",
    "        \n",
    "        # send the real t1 and fake t1 (from above) through the t1 discriminator\n",
    "        t1DiscReal = disc1(t1)\n",
    "        t1DiscFake = disc1(t1GenFake.detach())\n",
    "        \n",
    "        # calculate t1 discriminator loss (targets are ones for real and zeros for fake)\n",
    "        t1DiscRealLoss = mse(t1DiscReal, torch.ones_like(t1DiscReal))\n",
    "        t1DiscFakeLoss = mse(t1DiscFake, torch.zeros_like(t1DiscFake))\n",
    "        t1DiscLoss = t1DiscRealLoss + t1DiscFakeLoss\n",
    "                \n",
    "        # ------------------- t2 discriminator forward pass ------------------- #\n",
    "        # use the t1 -> t2 generator to generate a fake t2\n",
    "        t2GenFake = gen2(t1)\n",
    "        \n",
    "        # send the real t2 and fake t2 (from above) through the t2 discriminator\n",
    "        t2DiscReal = disc2(t2)\n",
    "        t2DiscFake = disc2(t2GenFake.detach())\n",
    "        \n",
    "        # calculate t2 discriminator loss (targets are ones for real and zeros for fake)\n",
    "        t2DiscRealLoss = mse(t2DiscReal, torch.ones_like(t2DiscReal))\n",
    "        t2DiscFakeLoss = mse(t2DiscFake, torch.zeros_like(t2DiscFake))\n",
    "        t2DiscLoss = t2DiscRealLoss + t2DiscFakeLoss\n",
    "        \n",
    "        # ------------------- backward pass for discriminators ------------------- #\n",
    "        discLoss = t1DiscLoss+t2DiscLoss\n",
    "        discOpt.zero_grad()\n",
    "        discLoss.backward()\n",
    "        discOpt.step()\n",
    "        \n",
    "        # ------------------- forward pass for generators ------------------- #\n",
    "        # calculate adversarial loss (generator's ability to fool discriminator)\n",
    "        t1DiscFake = disc1(t1GenFake)\n",
    "        t2DiscFake = disc2(t2GenFake)\n",
    "        \n",
    "        t1AdvLoss = mse(t1DiscFake, torch.ones_like(t1DiscFake))\n",
    "        t2AdvLoss = mse(t2DiscFake, torch.ones_like(t2DiscFake))\n",
    "        advLoss = t1AdvLoss + t2AdvLoss\n",
    "\n",
    "        # calculate cycle loss (ability of generator to create cycle-consistent images)\n",
    "        t1Cycle = gen1(t2GenFake)\n",
    "        t2Cycle = gen2(t1GenFake)\n",
    "        \n",
    "        t1CycleLoss = mae(t1, t1Cycle)\n",
    "        t2CycleLoss = mae(t2, t2Cycle)\n",
    "        cycleLoss = (t1CycleLoss + t2CycleLoss) * 10\n",
    "        \n",
    "        # ------------------- backward pass for generators ------------------- #\n",
    "        genLoss = advLoss + cycleLoss\n",
    "        genOpt.zero_grad()\n",
    "        genLoss.backward()\n",
    "        genOpt.step() \n",
    "        \n",
    "        # show losses and (optionally) real and generated images on final iteration\n",
    "        if index == len(loader.dataset)-1:\n",
    "            print(f'disc. loss: {discLoss.item()}\\tgen. loss: {genLoss.item()}')\n",
    "            \n",
    "            if plot:\n",
    "                # true t1 (from dataset)\n",
    "                plt.figure(figsize=(12,8))\n",
    "                plt.subplot(121)\n",
    "                plt.imshow(t1[0,:,:].cpu())\n",
    "                plt.title('True T1')\n",
    "                \n",
    "                # fake t2 (generated using true t1 as input)\n",
    "                plt.subplot(122)\n",
    "                plt.imshow(t2GenFake[0,:,:].detach().cpu())\n",
    "                plt.title('Fake T2')\n",
    "                plt.show()\n",
    "\n",
    "                # true t2 (from dataset)\n",
    "                plt.figure(figsize=(12,8))\n",
    "                plt.subplot(121)\n",
    "                plt.imshow(t2[0,:,:].cpu())\n",
    "                plt.title('True T2')\n",
    "\n",
    "                # fake t1 (generated using true t2 as input)\n",
    "                plt.subplot(122)\n",
    "                plt.imshow(t1GenFake[0,:,:].detach().cpu())\n",
    "                plt.title('Fake T1')\n",
    "                plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac33cd21-ecbf-4c91-95da-7c6e66834da9",
   "metadata": {},
   "source": [
    "### Testing Function\n",
    "\n",
    "The following function can be used to evaluate the generators of the cycle-GAN.\n",
    "\n",
    "The parameters to this function are as follows:\n",
    "- model: the directory of the generator model to be evaluated\n",
    "- loader: the validation data loader\n",
    "- lossFunction: the loss function with which to evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "555b36f1-c22a-4a21-b960-4022ee7228db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(modelDir, loader, lossFunction):    \n",
    "    print(f'\\n\\n\\n\\nBeginning Testing on {model.__class__.__name__}...')\n",
    "    \n",
    "    model = torch.load(modelDir)\n",
    "    averageLoss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for index, (t1, t2) in enumerate(loader):\n",
    "            t1 = t1.to(device)\n",
    "            t2 = t2.to(device)\n",
    "\n",
    "            # get model output, compute loss, add to running loss\n",
    "            output = model(t1)\n",
    "            loss = lossFunction(output, t2)\n",
    "            averageLoss += loss.item()\n",
    "            \n",
    "            # display every 20th image pair\n",
    "            if b % 20 == 0:\n",
    "                print(f'loss for b={b}:', loss.item())\n",
    "\n",
    "                # plot a random slice of the output and label\n",
    "                plt.figure(figsize=(12,8))\n",
    "\n",
    "                plt.subplot(131)\n",
    "                plt.imshow((t1[0,:,:]).cpu())\n",
    "                plt.title('T1 Image')\n",
    "\n",
    "                plt.subplot(132)\n",
    "                plt.imshow((t2[0,:,:]).cpu())\n",
    "                plt.title('T2 Image')\n",
    "\n",
    "                plt.subplot(133)\n",
    "                plt.imshow((output[0,:,:]).cpu())\n",
    "                plt.title('Predicted T2 Image')\n",
    "                plt.show()\n",
    "        \n",
    "        print(f'Average loss across all validation images: {averageLoss/batchSize}')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78d737e-f5c4-4438-b6d7-4ee77e3a3c19",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "This cell defines the device, training data loader, generators, discriminators, loss functions, and optimizers, and then invokes the training function to train the model. After every 10th epoch, starting at epoch 50, the two generators and discriminators will be saved in model/epoch{epoch_number}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb0e6f4-e781-4ab4-a3c1-c41ca1ebfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target device to run training on\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device: {device}')\n",
    "\n",
    "# training loader, used to extract and preprocess images from the archive\n",
    "trainDir = 'data/archive/MICCAI_BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "dataset = MRIDataset(t1Dir=trainDir, t2Dir=trainDir, train=True)\n",
    "loader = DataLoader(dataset,batch_size=1,shuffle=True)\n",
    "\n",
    "# cycle-GAN components\n",
    "gen1 = Generator().to(device)        # t2->t1 generator\n",
    "gen2 = Generator().to(device)        # t1->t2 generator\n",
    "disc1 = Discriminator().to(device)   # t1 discriminator\n",
    "disc2 = Discriminator().to(device)   # t2 discriminator\n",
    "\n",
    "# loss functions\n",
    "mse = nn.MSELoss()     # used for discriminator losses and adversarial loss\n",
    "mae = nn.L1Loss()      # used for cycle loss\n",
    "\n",
    "# discriminator and generator optimizers\n",
    "discOpt = optim.Adam(list(disc1.parameters()) + list(disc2.parameters()),lr=2e-4,betas=(0.5,0.999))\n",
    "genOpt = optim.Adam(list(gen1.parameters()) + list(gen2.parameters()),lr=2e-4,betas=(0.5,0.999))\n",
    "\n",
    "# train the model for 151 epochs\n",
    "nepochs = 151\n",
    "for epoch in range(nepochs):\n",
    "    print(f'\\n\\n\\n* =================================== EPOCH {epoch} =================================== *')\n",
    "    train(gen1, gen2, genOpt, disc1, disc2, discOpt, mse, mae, loader, device, True)\n",
    "    \n",
    "    # every 10th epoch after 50, save the models\n",
    "    if epoch >= 50 and epoch % 10 == 0:\n",
    "        \n",
    "        modelDir = f'model/epoch{epoch}/'\n",
    "        if not os.path.exists(modelDir):\n",
    "            os.makedirs(modelDir)\n",
    "\n",
    "        torch.save(gen1.state_dict(), modelDir + f'gen1epoch{epoch}.pth')\n",
    "        torch.save(gen2.state_dict(), modelDir + f'gen2epoch{epoch}.pth')\n",
    "        torch.save(disc1.state_dict(), modelDir + f'disc1epoch{epoch}.pth')\n",
    "        torch.save(disc2.state_dict(), modelDir + f'disc2epoch{epoch}.pth')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb9b6a7-994f-49f9-87a4-1792e7658780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 Third Try",
   "language": "python",
   "name": "py38third"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
